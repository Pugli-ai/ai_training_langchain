{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05530b1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b556fc2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd3783a",
   "metadata": {},
   "source": [
    "Remeber to set the OPENAI_API_KEY environment variable before running the code.\n",
    "`os.environ[\"OPENAI_API_KEY\"] = \"<>\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126a6a1",
   "metadata": {},
   "source": [
    "# Building A Language Model Application\n",
    "### LLMS: Get predictions from a language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bef95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3596e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ebe6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are 5 vacation destinations for someone who likes to eat pasta?\"\n",
    "output = llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Italy: As the birthplace of pasta, Italy is a must-visit for any pasta lover. With regions like Tuscany, Emilia-Romagna, and Sicily known for their specific types of pasta dishes, this country offers endless options for delectable pasta meals.\n",
      "\n",
      "2. New York City, USA: Known as a melting pot of cultures, New York City has a diverse range of Italian restaurants that serve up mouth-watering pasta dishes. From traditional Italian cuisine to modern and creative interpretations of pasta, this city has it all.\n",
      "\n",
      "3. Buenos Aires, Argentina: Buenos Aires has a strong Italian influence, making it a great destination for pasta lovers. With a variety of homemade pastas and traditional Italian dishes influenced by local flavors like beef and ample use of herbs, this city offers a unique twist on classic pasta dishes.\n",
      "\n",
      "4. Paris, France: While primarily known for its French cuisine, Paris has a thriving Italian food scene. Along with traditional French dishes, visitors can find delicious handmade pasta dishes at many Italian restaurants scattered throughout the city.\n",
      "\n",
      "5. Tokyo, Japan: Although not typically associated with pasta dishes, Tokyo has a surprising number of high-end Italian restaurants. These establishments often use fresh ingredients and incorporate local Japanese flavors, resulting in a unique\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c13e6",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "#### Create a prompt and generate a completion using the OpenAI interface of langchain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ad5b9",
   "metadata": {},
   "source": [
    "### Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34f7d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20076fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(temperature=0, model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "739a866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b495e4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Rainbow Steps\"\n"
     ]
    }
   ],
   "source": [
    "text = \"What would be a good company name for a dmkk ks\"\n",
    "messages = [\n",
    "    HumanMessage(content=text)\n",
    "    ]\n",
    "\n",
    "output = chat_model.invoke(messages).content\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d4efb",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "#### Create a prompt and generate a completion using the ChatOpenAI interface of langchain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7657e1e9",
   "metadata": {},
   "source": [
    "### Prompt Templates: Manage prompts for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d6d3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5181a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\", \"country\"],\n",
    "    template=\"What are 5 vacation {country} for someone who likes to eat {food}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "160f8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = prompt.format(food=\"dessert\",country=\"italy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b2ed434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 5 vacation italy for someone who likes to eat dessert?\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4309f2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Florence: Known as the birthplace of gelato, Florence offers a plethora of delicious dessert options including traditional gelato flavors like pistachio and stracciatella, as well as tasty pastries like the famous Florentine almond biscotti.\n",
      "\n",
      "2. Naples: This southern Italian city is famous for its Neapolitan pizza, but it also has a rich history of dessert-making. Try the signature sfogliatelle, a flaky pastry filled with ricotta cheese and candied fruit, or indulge in a traditional zeppole, a deep-fried pastry topped with powdered sugar.\n",
      "\n",
      "3. Sicily: As the largest island in the Mediterranean, Sicily has a diverse culinary scene that includes a wide range of desserts. Don't miss out on trying cannoli, a sweet pastry filled with ricotta cream and chocolate chips, or marzipan fruits, a traditional Sicilian treat made from almond paste.\n",
      "\n",
      "4. Rome: In addition to its famous gelato shops, Rome is also known for its rich and decadent desserts. Take a stroll through the historic streets and stop in at a pasticceria to try traditional desserts like tiramisu, a layered coffee and cream dessert, or the sweet and creamy panna cotta.\n",
      "\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983b0a5",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "#### Create a prompt and generate a completion using the PromptTemplates, BE CREATIVE :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be8b90",
   "metadata": {},
   "source": [
    "### Same for chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82ac23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c85f3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b372919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e912a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e376eca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to French.'), HumanMessage(content='I love programming.')]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cbe120b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'aime la programmation.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ecfcad",
   "metadata": {},
   "source": [
    "## Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92906dbf",
   "metadata": {},
   "source": [
    "OutputParsers convert the raw output of a language model into a format that can be used downstream. There are a few main types of OutputParsers, including:\n",
    "\n",
    "- Convert text from LLM into structured information (e.g. JSON)\n",
    "- Convert a ChatMessage into just a string\n",
    "- Convert the extra information returned from a call besides the message (like OpenAI function invocation) into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bef95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56bed2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec6ded84",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_parser.parse(\"hi, how, are, you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e0d47c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'how', 'are', 'you?']\n",
      "hi\n",
      "how\n",
      "are\n",
      "you?\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "for word in output:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468391c",
   "metadata": {},
   "source": [
    "Apart from the parse method, each output parse comes with some instructions that should be added to the prompt to guide the LLM on how to generate the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56095fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bd9d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how to use the output parser with a chat model\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that helps finding places to visits based on a location\\n\\n{format_instructions}\"),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    "    )\n",
    "formatted_prompt = prompt.format_prompt(text=\"Paris\", format_instructions=output_parser.get_format_instructions())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52626f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant that helps finding places to visits based on a location\\n\\nYour response should be a list of comma separated values, eg: `foo, bar, baz`'), HumanMessage(content='Paris')]\n"
     ]
    }
   ],
   "source": [
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3455d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chat_model.invoke(formatted_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92c0a4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eiffel Tower',\n",
       " 'Louvre Museum',\n",
       " 'Notre-Dame Cathedral',\n",
       " 'Montmartre',\n",
       " 'Palace of Versailles',\n",
       " 'Sainte-Chapelle',\n",
       " 'Seine River',\n",
       " \"Musée d'Orsay\",\n",
       " 'Champs-Élysées',\n",
       " 'Sacré-Cœur Basilica']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d0619",
   "metadata": {},
   "source": [
    "Let's see other parsers..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d865e",
   "metadata": {},
   "source": [
    "#### JSON parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e408bb",
   "metadata": {},
   "source": [
    "Very useful for structured information. It will convert the raw output of the LLM into a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48ac4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8433ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recipe(BaseModel):\n",
    "    name: str = Field(description=\"The name of the recipe.\")\n",
    "    difficulty: int = Field(description=\"The difficulty level of the recipe from 1 to 10.\")\n",
    "    time: int = Field(description=\"The time needed to make the recipe in minutes.\")\n",
    "    ingredients: List[str] = Field(description=\"The list of ingredients needed for the recipe.\")\n",
    "    steps: List[str] = Field(description=\"The list of steps to make the recipe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da725cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The name of the recipe.\", \"type\": \"string\"}, \"difficulty\": {\"title\": \"Difficulty\", \"description\": \"The difficulty level of the recipe from 1 to 10.\", \"type\": \"integer\"}, \"time\": {\"title\": \"Time\", \"description\": \"The time needed to make the recipe in minutes.\", \"type\": \"integer\"}, \"ingredients\": {\"title\": \"Ingredients\", \"description\": \"The list of ingredients needed for the recipe.\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"steps\": {\"title\": \"Steps\", \"description\": \"The list of steps to make the recipe.\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"name\", \"difficulty\", \"time\", \"ingredients\", \"steps\"]}\\n```'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser = JsonOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "# let's see how the format instructions look like\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9fb495",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "#### Put a JSON parser in the prompt and generate a completion using the OpenAI interface of langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b01fb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that provides recipes based on a query\\n\\n{format_instructions}\"),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ])\n",
    "query = \"What a easy recipes for pasta?\"\n",
    "json_result = output_parser.parse(\n",
    "    llm.invoke(\n",
    "        prompt.format_messages(text=query, format_instructions=output_parser.get_format_instructions())\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed88d6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Cook pasta according to package instructions.',\n",
       " 'Heat pasta sauce in a separate pan.',\n",
       " 'Drain pasta and mix with sauce.',\n",
       " 'Sprinkle parmesan cheese on top and serve.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(json_result))\n",
    "json_result['steps']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475d299",
   "metadata": {},
   "source": [
    "The result is a python dict that can be used downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0c523",
   "metadata": {},
   "source": [
    "### Chains: Combine LLMs and prompts in multi-step workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a36b775",
   "metadata": {},
   "source": [
    "The power of langchain comes from the ability to chain together multiple LLMs and prompts to create complex workflows.\n",
    "\n",
    "It also comes with a few built-in chains that can be used to create common workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7239da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt.partial(format_instructions=output_parser.get_format_instructions())\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Egg Fried Rice', 'Spanish Omelette', 'Egg Fried Cauliflower Rice']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": \"What is a recipe with eggs and rice?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45befde3",
   "metadata": {},
   "source": [
    "#### Example extraction chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab152ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions.extraction import create_extraction_chain_pydantic\n",
    "\n",
    "chain = create_extraction_chain_pydantic(\n",
    "    pydantic_schema=Recipe,\n",
    "    llm=chat_model\n",
    ")\n",
    "# read text from txt file\n",
    "recipe_text = open(\"carbonara.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "959852cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_result = chain.invoke(recipe_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344a6b3",
   "metadata": {},
   "source": [
    "We have our structured output from a text without implementing anything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66ad5530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe name: SPAGHETTI ALLA CARBONARA\n",
      "Difficulty: 2\n",
      "Time: 20\n",
      "Ingredients: ['Pancetta or bacon', 'Olive oil', 'Butter', 'Garlic cloves, peeled and lightly crushed', 'White wine, dry', 'Salt', 'Thin spaghetti', 'Eggs', 'Peccorino romano cheese, freshly grated', 'Parmesan cheese, freshly grated', 'Black pepper, freshly ground', 'Parsley, chopped fine']\n"
     ]
    }
   ],
   "source": [
    "extracted_class = extracted_result['text'][0]\n",
    "print(\"Recipe name:\", extracted_class.name)\n",
    "print(\"Difficulty:\", extracted_class.difficulty)\n",
    "print(\"Time:\", extracted_class.time)\n",
    "print(\"Ingredients:\", extracted_class.ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850668f0",
   "metadata": {},
   "source": [
    "### Agents: Dynamically call chains based on user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19db4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U langchain-community tavily-python langchainhub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc09af9",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0740ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293c45e",
   "metadata": {},
   "source": [
    "#### Finally, let's initialize an agent with:\n",
    "1. The tools\n",
    "2. The language model\n",
    "3. The type of agent we want to use.\n",
    "4. The prompt that guides the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b20f48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_react_agent\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(chat_model, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2cf54",
   "metadata": {},
   "source": [
    "See list of agents types [here](https://python.langchain.com/docs/modules/agents/agent_types/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee557ecf",
   "metadata": {},
   "source": [
    "Finally, we combine the agent (the brains) with the tools inside the AgentExecutor (which will repeatedly call the agent and execute tools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92f0e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89728919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the most recent episode of One Piece, which is a current event. I should use the search engine to find this information.\n",
      "Action: Search\n",
      "Action Input: Latest episode of One Piece\u001b[0m\u001b[36;1m\u001b[1;3m['CP-0 led by Rob Lucci makes a forced landing at Egghead.', 'Preparations for Interception! Rob Lucci Strikes! type: One Piece: Season 21, Episode 11.', 'Preparations for Interception! Rob Lucci Strikes! entity_type: tv, tvm.', 'Preparations for Interception! Rob Lucci Strikes! main_tab_text: Overview.', 'Preparations for Interception! Rob Lucci Strikes! kgmid: /g/11vwjqlx73.', 'Preparations for Interception! Rob Lucci Strikes! show: One Piece.', 'One Piece is an anime television series based on the manga series of the same name. As of 2024 it has more than 1,000 episodes.', 'Stream and watch the anime One Piece on Crunchyroll. Monkey. D. Luffy refuses to let anyone or anything stand in the way of his quest to become the king of ...', 'When will One Piece episode 1,100 come out? One Piece season 21 is back for its historic 1,100th episode on Sunday 7th April. Unprecedented Power! Luffy vs ...', 'For seasons 1 to 8, see List of One Piece episodes (seasons 1–8). ... The Final Decisive Battle Against Hordy!\" ... ^ This episode originally aired as second half ...', 'This is a complete Episode Guide for all the animation produced for One Piece (ワンピース, Wanpīsu?) based on the manga authored by Eiichiro Oda.', 'The newest episodes of One Piece cover the Egghead Island arc from the manga, which means we are deep into what creator Eiichiro Oda considers ...', 'One Piece. Release Time. Release Time. Episode 1100 Raw: Saturday 06 Apr, 05: ...', 'One Piece Full Episodes ; Gear 5 Luffy vs Kaido - One Piece Episode 1071 (Luffy Gear 5) [1080p]. AnimeConnectPeople ; But I Can Become Giant. Omomos ; Luffy vs ...', 'Watch and Download All New Episode Of One Piece in English Subbed and Dubbed Only at Watchop.']\u001b[0m\u001b[32;1m\u001b[1;3mThe latest episode of One Piece is \"Preparations for Interception! Rob Lucci Strikes!\" from Season 21, Episode 11.\n",
      "Final Answer: The latest episode of One Piece is \"Preparations for Interception! Rob Lucci Strikes!\" from Season 21, Episode 11.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the latest episode of One Piece?',\n",
       " 'output': 'The latest episode of One Piece is \"Preparations for Interception! Rob Lucci Strikes!\" from Season 21, Episode 11.'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "agent_executor.invoke({\"input\":\"What is the latest episode of One Piece?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
